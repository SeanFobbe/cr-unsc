---
title: "Quality Assurance | Corpus of Resolutions: UN Security Council"
author: "Seán Fobbe, Lorenzo Gasbarri and Niccoló Ridi"
geometry: margin=3cm
papersize: a4
fontsize: 11pt
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: ../tex/Preamble_EN.tex
      before_body: [../temp/Definitions.tex,../tex/Titlepage_Tests.tex]
bibliography: ../temp/packages.bib
nocite: '@*'
---



```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.path = file.path("..", "analysis/"),
                      dev = config$fig$format,
                      dpi = config$fig$dpi,
                      fig.align = config$fig$align,
                      echo = TRUE,
                      warning = TRUE,
                      message = TRUE)

```




# Overview

This report contains information on all automated tests that are run during the dataset compilation process. Many are hard tests (failure means that an error interrupts compilation), but just as many tests require interpretation and a judgment call to determine whether surprising behavior has occurred.

Hard tests are integrated into the final part of target creation functions to act as data quality gateways. Soft tests are run on the final data and their results reported here.



## Load results

```{r}
tar_load(latexdefs)
tar_load(dt.var_codebook)
tar_load(res.no.full)
tar_load(dt.record.final)
tar_load(dt.download.final)
tar_load(pdf_res_ar)
tar_load(pdf_res_en)
tar_load(pdf_res_es)
tar_load(pdf_res_fr)
tar_load(pdf_res_ru)
tar_load(pdf_res_zh)
tar_load(lingstats.summary)
tar_load(langtest)
tar_load(ocrtest)
tar_load(dt.final)
tar_load(igraph_citations)

```

## Count Automated Tests


```{r}

Rfiles <- list.files("functions", pattern = "\\.R$", full.names = TRUE)
code <- unlist(lapply(Rfiles, readLines))


```


### Tests


```{r}

sum(stringi::stri_count(regex = "test_that\\(", code))

```

### Expectations

```{r}

sum(stringi::stri_count(regex = "expect_", code))

```





# Visualize Pipeline

Visualize the data pipeline. This is a glance test. If something is obviously wrong with the data pipeline, the visual will look terrible at a glance. 

Also good at showing "dangling" targets that were supposed to be connected to something but were overlooked during development.



```{r, CR-UNSC_Workflow_blue, fig.width = 16, fig.height = 18, fig.pos = "p", fig.cap = "Data set compilation process."}


edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)

ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "#55c8ff")+
    geom_node_point(size = 2,
                    color = "white")+
    geom_node_text(aes(label = name),
                   color = "white",
                   size = 2,
                   repel = TRUE)+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Data set compilation process"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "white"),                        
        plot.background = element_rect(fill = "black"),
        plot.caption = element_text(color = "white"),
        plot.margin = margin(10, 20, 10, 10)
    )

```



# Visualize Citation Network

Visualize the citation network. This is a glance test. If something is obviously wrong with the citation network data, the visual will look terrible at  a glance.


```{r, CR-UNSC_Citations_Network_blue, fig.width = 20, fig.height = 20, fig.pos = "p", fig.cap = "The citation network of the UNSC"}

##  kk very nice,

## stress interesting with bbox = 25, png 20x20, res 300, niter 4000

## gem and dh veeeery slow;

## fr, lgl not nice
                                        
# drl, gfr; 

## index <- which(igraph::V(igraph_citations)$body == "S")

## g <- igraph::subgraph(igraph_citations, index)

g <- igraph_citations

#pdf("test.pdf", width = 20, height = 20)

#png("test-20x20-anon.png", units = "in", width = 25, height = 25, res = 300)

ggraph(g, "stress", niter = 4000, bbox = 25) + 
    geom_edge_diagonal(colour = "#55c8ff", edge_width = 0.1)+
    geom_node_point(size = 0.1,
                    color = "white")+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| The complete UNSC citation network"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "white"),                        
        plot.background = element_rect(fill = "black"),
        plot.caption = element_text(color = "white"),
        plot.margin = margin(10, 20, 10, 10)
    )


#dev.off()


    


```






# Completeness 


## Completeness of PDF Download

Examines whether all PDF files named in the download manifest have been successfully acquired. If PDF files are missing, it could mean:

- PDF url in manifest is incorrect
- PDF file is not available in the database
- PDF download failed for any reason and several retries could not resolve the issue



```{r}

setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_AR.pdf"), basename(pdf_res_ar))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_EN.pdf"), basename(pdf_res_en))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_ES.pdf"), basename(pdf_res_es))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_FR.pdf"), basename(pdf_res_fr))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_RU.pdf"), basename(pdf_res_ru))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_ZH.pdf"), basename(pdf_res_zh))

```


## Completeness of Data Set

Examines whether all resolutions in the manifest have been acquired from at least one language. This is a test of existence, so will not detect missing language versions.

If resolutions are missing in this test, it could mean:

- Something went badly wrong during the download phase
- The UN Digital Library database does not contain the indicated resolutions


```{r}
setdiff(res.no.full, dt.final$res_no)
```




# Missing Values

Reports the number of missing values for each variable in the dataset. Values can be missing for many reasons:

- Never collected and therefore neither present in the UN Digital Library database
- Not contained in UN Digital Library database for any other reason
- Error during processing
- Not being applicable to the record in question (e.g. "contains" variable, which is only applicable to resolutions that contain appended texts, such as court statutes).

The results require some interpretation and deep examination of the data to decide whether missingness is a problem that can be solved with amending the data pipeline or needs to be addressed in the source database.



```{r, results = "asis"}

missingvalues <- f.missingvalues(x = dt.final,
                                 kable = TRUE,
                                 dir.out = dir.analysis,
                                 prefix.files = prefix.files)


```




# Text Quality Comparison

To compare the text quality of extracted, OCR and gold (expert revised) variants we calculate the number of features (unique tokens) for each language and type of process when run through a standard pre-processing workflow. During pre-processing we remove numbers, punctuation, symbols and separators, lowercase all tokens and remove stopwords in English, French and Spanish.

The resulting number of features determines the quality and speed with which document-feature matrix (or document-term matrix) oriented workflows can proceed. Lower is better.


```{r}

print(ocrtest)

```


# Language Purity Test

This test classifies each element of each text variable with the {textcat} package. While each resolution text should be monolingual, the unprocessed nature of most PDFs (multiple resolutions per PDF, multiple languages per PDF) means that the non-English text variables are likely contaminated with superfluous text. The uses they are put to should be carefully considered.

The test may not work well for non-Western languages and scripts.





## English

```{r}

langtest[,.N,keyby = "en_langtest"]

```

## French

```{r}

langtest[,.N,keyby = "fr_langtest"]

```


## Spanish

```{r}

langtest[,.N,keyby = "es_langtest"]

```







# Documents with Low Character Count

Documents with low character count indicate potential errors in processing. This could mean:

- Absence of documents in UN Digital Library
- Empty PDF file
- Extraction/OCR failure
- Refining failure

Since the documents in the set are by definition low in character count, they are printed in full to expedite the decision whether they contain unusually low substantive content or indicate data quality issues.



## Arabic

```{r}
dt.final[nchar(dt.final$text_ar) < 200, .(doc_id, text_ar)]

```


## English

```{r}
dt.final[nchar(dt.final$text) < 200, .(doc_id, text)]

```

## Spanish

```{r}
dt.final[nchar(dt.final$text_es) < 200, .(doc_id, text_es)]

```


## French

```{r}
dt.final[nchar(dt.final$text_fr) < 200, .(doc_id, text_fr)]

```


## Russian

```{r}
dt.final[nchar(dt.final$text_ru) < 200, .(doc_id, text_ru)]

```


## Chinese

```{r}
dt.final[nchar(dt.final$text_zh) < 200, .N]

```






# Frequency Tables


## Selected Variables

 **Note:** Frequency tables are calculate only for these variables.

```{r}
varnames <- dt.var_codebook[freqtable == 1]$varname
varnames <- gsub("\\\\", "", varnames)
print(varnames)


```




```{r}

## Define prefix

prefix <- paste0(config$project$shortname,
                 "_FrequencyTable_var-")

```

## Run Frequency Tables


```{r, results = "asis"}

f.fast.freqtable(dt.final,
                 varlist = varnames,
                 sumrow = TRUE,
                 output.list = FALSE,
                 output.kable = TRUE,
                 output.csv = TRUE,
                 outputdir = dir.analysis,
                 prefix = prefix,
                 align = c("p{5cm}",
                           rep("r", 4)))

```











```{r, results = "asis"}
cat(readLines(tar_read(changelog)),
    sep = "\n")

```






# Replication Parameters


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Bibliography
