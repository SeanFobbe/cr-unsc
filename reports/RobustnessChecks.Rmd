---
title: "Robustness Checks | Corpus of Resolutions: UN Security Council"
author: "Seán Fobbe, Niccolò Ridi and Lorenzo Gasbarri"
geometry: margin=3cm
papersize: a4
fontsize: 11pt
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: ../tex/Preamble_EN.tex
      before_body: [../temp/Definitions.tex,../tex/Titlepage_Robustness.tex]
bibliography: ../temp/packages.bib
nocite: '@*'
---



```{r, setup, include=FALSE}
knitr::opts_chunk$set(fig.path = file.path("..", "analysis/"),
                      dev = config$fig$format,
                      dpi = config$fig$dpi,
                      fig.align = config$fig$align,
                      echo = TRUE,
                      warning = TRUE,
                      message = TRUE)

```


# Overview

## Load results

```{r}
tar_load(latexdefs)
tar_load(dt.var_codebook)
tar_load(lingstats.summary)
tar_load(dt.record.final)
tar_load(dt.download.final)
tar_load(pdf_res_ar)
tar_load(pdf_res_en)
tar_load(pdf_res_es)
tar_load(pdf_res_fr)
tar_load(pdf_res_ru)
tar_load(pdf_res_zh)
tar_load(dt.final)
tar_load(langtest)
tar_load(ocrtest)
tar_load(igraph_citations)

```

## Count Automated Tests


```{r}

Rfiles <- list.files("functions", pattern = "\\.R$", full.names = TRUE)
code <- unlist(lapply(Rfiles, readLines))


```


### Tests


```{r}

sum(stringi::stri_count(regex = "test_that\\(", code))

```

### Expectations

```{r}

sum(stringi::stri_count(regex = "expect_", code))

```



# Introduction

Lorem Ipsum. test




# Visualize Pipeline



```{r, CR-UNSC_00_Pipeline_Graph_blue, fig.width = 16, fig.height = 18, fig.pos = "p", fig.cap = "Data set compilation process."}


edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)

ggraph(g,
       'sugiyama') + 
    geom_edge_diagonal(colour = "#55c8ff")+
    geom_node_point(size = 2,
                    color = "white")+
    geom_node_text(aes(label = name),
                   color = "white",
                   size = 2,
                   repel = TRUE)+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| Complete data set compilation process"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "white"),                        
        plot.background = element_rect(fill = "black"),
        plot.caption = element_text(color = "white"),
        plot.margin = margin(10, 20, 10, 10)
    )

```



# Citation Network



```{r, CR-UNSC_30_Citations_blue, fig.width = 14, fig.height = 14, fig.pos = "p", fig.cap = "The citation network of the UNSC (Kamada Kawai layout)"}

# Options: kk very nice, lgl, drl, gfr; gem veeeery slow; fr not nice

#index <- which(igraph::V(igraph.citations)$senat == "XI")

#g <- igraph::subgraph(igraph.citations.cleaned, index)

g <- igraph_citations

ggraph(g, "kk", kkconst = igraph::vcount(g)/2 ) + 
    geom_edge_diagonal(colour = "#55c8ff")+
    geom_node_point(size = 0.5,
                    color = "white")+
    theme_void()+
    labs(
        title = paste(prefix.figuretitle,
                      "| The complete UNSC citation network"),
        caption = caption
    )+
    theme(
        plot.title = element_text(size = 14,
                                  face = "bold",
                                  color = "white"),                        
        plot.background = element_rect(fill = "black"),
        plot.caption = element_text(color = "white"),
        plot.margin = margin(10, 20, 10, 10)
    )



```






# Completeness of Download


## Download: Missing PDF Files

```{r}

setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_AR.pdf"), basename(pdf_res_ar))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_EN.pdf"), basename(pdf_res_en))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_ES.pdf"), basename(pdf_res_es))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_FR.pdf"), basename(pdf_res_fr))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_RU.pdf"), basename(pdf_res_ru))
setdiff(paste0(dt.download.final[!is.na(url_res_ar)]$doc_id, "_ZH.pdf"), basename(pdf_res_zh))

```



# Missing Values



```{r, results = "asis"}

missingvalues <- f.missingvalues(x = dt.final,
                                 kable = TRUE,
                                 dir.out = dir.analysis,
                                 prefix.files = prefix.files)


```



f.token.processor <- function(corpus){
    tokens <- tokens(corpus,
                     remove_numbers = TRUE,
                     remove_punct = TRUE,
                     remove_symbols = TRUE,
                     remove_separators = TRUE)
    tokens <- tokens_tolower(tokens)
    tokens <- tokens_remove(tokens,
                            pattern = c(stopwords("english"),
                                        stopwords("french"),
                                        stopwords("spanish")))
    return(tokens)
}


# Text Quality Comparison

To compare the text quality of extracted, OCR and gold (expert revised) variants we calculate the number of features (unique tokens) for each language and process following a standard pre-processing workflow. During pre-processing we remove numbers, punctuation, symbols and separators, lowercase all tokens and remove stopwords in English, French and Spanish.

The resulting number of features determines the quality and speed with which document-feature matrix (or document-term matrix) oriented workflows can proceed. Lower is better.


```{r}

print(ocrtest)

```


# Language Purity Test

This test classifies each element of each text variable with the {textcat} package. While each resolution text should be monolingual, the unprocessed nature of most PDFs (multiple resolutions per PDF, multiple languages per PDF) means that the non-English text variables are likely contaminated with superfluous text. The uses they are put to should be carefully considered.

The test may not work well for non-Western languages and scripts.





## English

```{r}

langtest[,.N,keyby = "en_langtest"]

```

## French

```{r}

langtest[,.N,keyby = "fr_langtest"]

```


## Spanish

```{r}

langtest[,.N,keyby = "es_langtest"]

```







# Documents with Low Character Count


## Arabic

```{r}
dt.final[nchar(dt.final$text_ar) < 200, .(doc_id, text_ar)]

```


## English

```{r}
dt.final[nchar(dt.final$text) < 200, .(doc_id, text)]

```

## Spanish

```{r}
dt.final[nchar(dt.final$text_es) < 200, .(doc_id, text_es)]

```


## French

```{r}
dt.final[nchar(dt.final$text_fr) < 200, .(doc_id, text_fr)]

```


## Russian

```{r}
dt.final[nchar(dt.final$text_ru) < 200, .(doc_id, text_ru)]

```


## Chinese

```{r}
dt.final[nchar(dt.final$text_zh) < 200, .N]

```






# Frequency Tables


## Selected Variables

 **Note:** Frequency tables are calculate only for these variables.

```{r}
varnames <- dt.var_codebook[freqtable == 1]$varname
varnames <- gsub("\\\\", "", varnames)
print(varnames)


```




```{r}

## Define prefix

prefix <- paste0(config$project$shortname,
                 "_01_FrequencyTable_var-")

```

## Run Frequency Tables


```{r, results = "asis"}

f.fast.freqtable(dt.final,
                 varlist = varnames,
                 sumrow = TRUE,
                 output.list = FALSE,
                 output.kable = TRUE,
                 output.csv = TRUE,
                 outputdir = dir.analysis,
                 prefix = prefix,
                 align = c("p{5cm}",
                           rep("r", 4)))

```











```{r, results = "asis"}
cat(readLines(tar_read(changelog)),
    sep = "\n")

```






# Replication Parameters


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Bibliography
